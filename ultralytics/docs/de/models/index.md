---
comments: true
description: Entdecken Sie die vielf√§ltige Palette an Modellen der YOLO-Familie, SAM, MobileSAM, FastSAM, YOLO-NAS und RT-DETR, die von Ultralytics unterst√ºtzt werden. Beginnen Sie mit Beispielen f√ºr die CLI- und Python-Nutzung.
keywords: Ultralytics, Dokumentation, YOLO, SAM, MobileSAM, FastSAM, YOLO-NAS, RT-DETR, Modelle, Architekturen, Python, CLI
---

# Von Ultralytics unterst√ºtzte Modelle

Willkommen bei der Modell-Dokumentation von Ultralytics! Wir bieten Unterst√ºtzung f√ºr eine breite Palette von Modellen, die jeweils f√ºr spezifische Aufgaben wie [Objekterkennung](../tasks/detect.md), [Instanzsegmentierung](../tasks/segment.md), [Bildklassifizierung](../tasks/classify.md), [Posensch√§tzung](../tasks/pose.md) und [Multi-Objekt-Tracking](../modes/track.md) ma√ügeschneidert sind. Wenn Sie daran interessiert sind, Ihre Modellarchitektur bei Ultralytics beizutragen, sehen Sie sich unseren [Beitragenden-Leitfaden](../../help/contributing.md) an.

!!! Note "Hinweis"

    üöß Unsere Dokumentation in verschiedenen Sprachen ist derzeit im Aufbau und wir arbeiten hart daran, sie zu verbessern. Vielen Dank f√ºr Ihre Geduld! üôè

## Vorgestellte Modelle

Hier sind einige der wichtigsten unterst√ºtzten Modelle:

1. **[YOLOv3](yolov3.md)**: Die dritte Iteration der YOLO-Modellfamilie, urspr√ºnglich von Joseph Redmon, bekannt f√ºr ihre effiziente Echtzeit-Objekterkennungsf√§higkeiten.
2. **[YOLOv4](yolov4.md)**: Ein dunkelnetz-natives Update von YOLOv3, ver√∂ffentlicht von Alexey Bochkovskiy im Jahr 2020.
3. **[YOLOv5](yolov5.md)**: Eine verbesserte Version der YOLO-Architektur von Ultralytics, die bessere Leistungs- und Geschwindigkeitskompromisse im Vergleich zu fr√ºheren Versionen bietet.
4. **[YOLOv6](yolov6.md)**: Ver√∂ffentlicht von [Meituan](https://about.meituan.com/) im Jahr 2022 und in vielen autonomen Lieferrobotern des Unternehmens im Einsatz.
5. **[YOLOv7](yolov7.md)**: Aktualisierte YOLO-Modelle, die 2022 von den Autoren von YOLOv4 ver√∂ffentlicht wurden.
6. **[YOLOv8](yolov8.md) NEU üöÄ**: Die neueste Version der YOLO-Familie, mit erweiterten F√§higkeiten wie Instanzsegmentierung, Pose/Schl√ºsselpunktsch√§tzung und Klassifizierung.
7. **[Segment Anything Model (SAM)](sam.md)**: Metas Segment Anything Model (SAM).
8. **[Mobile Segment Anything Model (MobileSAM)](mobile-sam.md)**: MobileSAM f√ºr mobile Anwendungen, von der Kyung Hee University.
9. **[Fast Segment Anything Model (FastSAM)](fast-sam.md)**: FastSAM von der Image & Video Analysis Group, Institute of Automation, Chinesische Akademie der Wissenschaften.
10. **[YOLO-NAS](yolo-nas.md)**: YOLO Neural Architecture Search (NAS) Modelle.
11. **[Realtime Detection Transformers (RT-DETR)](rtdetr.md)**: Baidus PaddlePaddle Realtime Detection Transformer (RT-DETR) Modelle.

<p align="center">
  <br>
  <iframe width="720" height="405" src="https://www.youtube.com/embed/MWq1UxqTClU?si=nHAW-lYDzrz68jR0"
    title="YouTube-Video-Player" frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
  <br>
  <strong>Anschauen:</strong> F√ºhren Sie Ultralytics YOLO-Modelle in nur wenigen Codezeilen aus.
</p>

## Einstieg: Nutzungbeispiele

Dieses Beispiel bietet einfache YOLO-Trainings- und Inferenzbeispiele. F√ºr vollst√§ndige Dokumentationen √ºber diese und andere [Modi](../modes/index.md) siehe die Dokumentationsseiten [Predict](../modes/predict.md),  [Train](../modes/train.md), [Val](../modes/val.md) und [Export](../modes/export.md).

Beachten Sie, dass das folgende Beispiel f√ºr YOLOv8 [Detect](../tasks/detect.md) Modelle zur Objekterkennung ist. F√ºr zus√§tzliche unterst√ºtzte Aufgaben siehe die Dokumentation zu [Segment](../tasks/segment.md), [Classify](../tasks/classify.md) und [Pose](../tasks/pose.md).

!!! Example "Beispiel"

    === "Python"

        Vorgefertigte PyTorch `*.pt` Modelle sowie Konfigurationsdateien `*.yaml` k√∂nnen den Klassen `YOLO()`, `SAM()`, `NAS()` und `RTDETR()` √ºbergeben werden, um eine Modellinstanz in Python zu erstellen:

        ```python
        from ultralytics import YOLO

        # Laden eines COCO-vortrainierten YOLOv8n Modells
        model = YOLO('yolov8n.pt')

        # Modellinformationen anzeigen (optional)
        model.info()

        # Model auf dem COCO8-Beispieldatensatz f√ºr 100 Epochen trainieren
        results = model.train(data='coco8.yaml', epochs=100, imgsz=640)

        # Inferenz mit dem YOLOv8n Modell auf das Bild 'bus.jpg' ausf√ºhren
        results = model('path/to/bus.jpg')
        ```

    === "CLI"

        CLI-Befehle sind verf√ºgbar, um die Modelle direkt auszuf√ºhren:

        ```bash
        # Ein COCO-vortrainiertes YOLOv8n Modell laden und auf dem COCO8-Beispieldatensatz f√ºr 100 Epochen trainieren
        yolo train model=yolov8n.pt data=coco8.yaml epochs=100 imgsz=640

        # Ein COCO-vortrainiertes YOLOv8n Modell laden und Inferenz auf das Bild 'bus.jpg' ausf√ºhren
        yolo predict model=yolov8n.pt source=path/to/bus.jpg
        ```

## Neue Modelle beitragen

Sind Sie daran interessiert, Ihr Modell bei Ultralytics beizutragen? Gro√üartig! Wir sind immer offen daf√ºr, unser Modellportfolio zu erweitern.

1. **Repository forken**: Beginnen Sie mit dem Forken des [Ultralytics GitHub-Repositorys](https://github.com/ultralytics/ultralytics).

2. **Ihren Fork klonen**: Klonen Sie Ihren Fork auf Ihre lokale Maschine und erstellen Sie einen neuen Branch, um daran zu arbeiten.

3. **Ihr Modell implementieren**: F√ºgen Sie Ihr Modell entsprechend den in unserem [Beitragenden-Leitfaden](../../help/contributing.md) bereitgestellten Kodierungsstandards und Richtlinien hinzu.

4. **Gr√ºndlich testen**: Stellen Sie sicher, dass Sie Ihr Modell sowohl isoliert als auch als Teil des Pipelines gr√ºndlich testen.

5. **Eine Pull-Anfrage erstellen**: Sobald Sie mit Ihrem Modell zufrieden sind, erstellen Sie eine Pull-Anfrage zum Hauptrepository zur √úberpr√ºfung.

6. **Code-Review & Zusammenf√ºhren**: Nach der √úberpr√ºfung, wenn Ihr Modell unseren Kriterien entspricht, wird es in das Hauptrepository zusammengef√ºhrt.

F√ºr detaillierte Schritte konsultieren Sie unseren [Beitragenden-Leitfaden](../../help/contributing.md).
